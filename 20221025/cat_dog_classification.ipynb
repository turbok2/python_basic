{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZogwbgedLAc"
   },
   "source": [
    "[구글 코랩에서 열기](https://colab.research.google.com/github/turbok2/python_basic/blob/main/20221025/cat_dog_classification.ipynb)   2022.10.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코랩에서 열리면 상단 메뉴 - 파일 - 드라이브에 사본 저장 선택  \n",
    "- 새탭으로 열기 선택  \n",
    "- 이 파일은 강사의 소유이므로 여기서 여러 사람이 실행하면 문제 발생함,  복사본을 만들어 자신의 구글드라이브에 복사된 걸 사용해야 함  \n",
    "- 상단의 파일이름을 클릭하고 원하는 이름으로 변경  \n",
    "- diabetes.csv 처럼 외부 파일이 필요하면 Colab의 좌측 메뉴에서 [문서철]아이콘을 누르고 sample_data 아래 영역에 다운 받은 파일(diabetes.csv)을 drag & drop 하시면 됩니다. (단 이 파일은 임시적으로 저장된 것이라 다음에 다시 접속하면 없습니다. 영구적으로 사용하려면 구글드라이브에 복사하고 연결하셔야 합니다.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQriYz4DWBgo"
   },
   "source": [
    "# 데이터받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDnY-5FbVf1k"
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "-O /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCMHMrChVrr2"
   },
   "source": [
    "우선 Colab 코드셀에 위의 명령어를 입력해서 데이터셋을 다운로드합니다.\n",
    "아래 그림과 같이 페이지 왼쪽의 목차 탭을 열어서 tmp 폴더에\n",
    "cats_and_dogs_filtered.zip 파일이 다운로드되어 있는지 확인합니다.\n",
    "cats_and_dogs_filtered 데이터셋은 25,000개의 이미지를 포함하는 원본 Dogs Vs. Cats 데이터셋에서 약 3,000개의 이미지를 추출한 간소화된 버전의 데이터셋입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFR9BK7kVvFw"
   },
   "outputs": [],
   "source": [
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQriYz4DWBgo"
   },
   "source": [
    "# 압축풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7j6ZXZKVzda"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-CDzDAmWFtc"
   },
   "source": [
    "os 라이브러리를 통해 파일시스템에 접근할 수 있습니다.\n",
    "zipfile 라이브러리의 ZipFile 클래스로 ZIP 파일을 연 후에\n",
    "extractall() 메서드를 이용해서 tmp 폴더에 압축을 풉니다.\n",
    "아래와 같이 cats_and_dogs_filtered 폴더가 만들어졌다면 준비가 된 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YM_lL793WETS"
   },
   "outputs": [],
   "source": [
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPhFo2ofWWOB"
   },
   "source": [
    "# 경로 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCzvLq3BWPwE"
   },
   "outputs": [],
   "source": [
    "# 기본 경로\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# 훈련에 사용되는 고양이/개 이미지 경로\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "print(train_cats_dir)\n",
    "print(train_dogs_dir)\n",
    "\n",
    "# 테스트에 사용되는 고양이/개 이미지 경로\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "print(validation_cats_dir)\n",
    "print(validation_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z3XgdA5Wa6O"
   },
   "source": [
    "기본 경로와 훈련에 사용되는 고양이/개 이미지의 경로를 각각 지정해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJeZVzCkWduY"
   },
   "source": [
    "#Kaggle Dogs Vs. Cats 데이터셋 살펴보기  \n",
    "파일 이름과 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y7m53ocWYsj"
   },
   "outputs": [],
   "source": [
    "train_cat_fnames = os.listdir( train_cats_dir )\n",
    "train_dog_fnames = os.listdir( train_dogs_dir )\n",
    "\n",
    "print(train_cat_fnames[:5])\n",
    "print(train_dog_fnames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYrpd56fWjsb"
   },
   "source": [
    "os.listdir() 메서드는 경로 내에 있는 파일의 이름을 리스트의 형태로 반환합니다.\n",
    "각각 다섯 개씩 출력했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "espOMYDlWh-d"
   },
   "outputs": [],
   "source": [
    "print('Total training cat images :', len(os.listdir(train_cats_dir)))\n",
    "print('Total training dog images :', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print('Total validation cat images :', len(os.listdir(validation_cats_dir)))\n",
    "print('Total validation dog images :', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jg1LJXaWol_"
   },
   "source": [
    "각 경로에 있는 파일명 리스트의 길이를 통해 파일의 개수를 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jyM3TCzWr7P"
   },
   "source": [
    "# 이미지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6gQTqEyWmqd"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nrows, ncols = 4, 4\n",
    "pic_index = 0\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*3, nrows*3)\n",
    "\n",
    "pic_index+=8\n",
    "\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname)\n",
    "                for fname in train_cat_fnames[ pic_index-8:pic_index]]\n",
    "\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname)\n",
    "                for fname in train_dog_fnames[ pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off')\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDry3H8UW51j"
   },
   "source": [
    "Matplotlib 라이브러리를 이용해서 이미지를 출력해보면, 데이터셋에 위와 같은 이미지들이 포함되어 있음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-il0V92W-uf"
   },
   "source": [
    "# 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8ABibQ7W2xl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMwU4u1iXDmL"
   },
   "source": [
    "이제 TensorFlow를 이용해서 합성곱 신경망의 모델을 구성합니다.\n",
    "\n",
    "summary() 메서드를 이용해서 신경망의 구조를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p534lDiXGO6"
   },
   "source": [
    "# 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aER4mJOkXBkW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9kQG0KwXK7B"
   },
   "source": [
    "모델 컴파일 단계에서는 compile() 메서드를 이용해서 손실 함수 (loss function)와 옵티마이저 (optimizer)를 지정합니다.\n",
    "\n",
    "말과 사람 이미지 분류하기 예제에서와 같이 손실 함수로 ‘binary_crossentropy’를 사용했습니다.\n",
    "\n",
    "출력층의 활성화함수로 ‘sigmoid’를 사용했고, 이는 0과 1 두 가지로 분류되는 ‘binary’ 분류 문제에 적합하기 때문입니다.\n",
    "\n",
    "또한, 옵티마이저로는 RMSprop을 사용했습니다.\n",
    "\n",
    "RMSprop (Root Mean Square Propagation) Algorithm은 훈련 과정 중에 학습률을 적절하게 변화시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_6KAMqxXNRq"
   },
   "source": [
    "#이미지 데이터 전처리하기  \n",
    "훈련을 진행하기 전, tf.keras.preprocessing.image 모듈의 ImageDataGenerator 클래스를 이용해서 데이터 전처리를 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rONgYMjsXIke"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary',\n",
    "                                                  target_size=(150, 150))\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                       batch_size=20,\n",
    "                                                       class_mode  = 'binary',\n",
    "                                                       target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRMU3WNXXTqk"
   },
   "source": [
    "우선 ImageDataGenerator 객체의 rescale 파라미터를 이용해서 모든 데이터를 255로 나누어준 다음,\n",
    "\n",
    "flow_from_directory() 메서드를 이용해서 훈련과 테스트에 사용될 이미지 데이터를 만듭니다.\n",
    "\n",
    "첫번째 인자로 이미지들이 위치한 경로를 입력하고, batch_size, class_mode를 지정합니다.\n",
    "\n",
    "target_size에 맞춰서 이미지의 크기가 조절됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPIM_YbWXUwC"
   },
   "source": [
    "# 모델 훈련하기  \n",
    "fit() 메서드는 앞에서 구성한 Neural Network 모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBBQVJOlXQUp"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=10,  #100,\n",
    "                    validation_steps=50,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWElkqeuXaxE"
   },
   "source": [
    "훈련과 테스트를 위한 데이터셋인 train_generator, validation_generator를 입력합니다.\n",
    "\n",
    "epochs는 데이터셋을 한 번 훈련하는 과정을 의미합니다.\n",
    "\n",
    "steps_per_epoch는 한 번의 에포크 (epoch)에서 훈련에 사용할 배치 (batch)의 개수를 지정합니다.\n",
    "\n",
    "validation_steps는 한 번의 에포크가 끝날 때, 테스트에 사용되는 배치 (batch)의 개수를 지정합니다.\n",
    "\n",
    "위와 같은 훈련 과정을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f3nArYgXeTk"
   },
   "source": [
    "# 정확도와 손실 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxXKW2NEXYs4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'go', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aBY3gkzXlKT"
   },
   "source": [
    "Matplotlib 라이브러리를 이용해서 훈련 과정에서 에포크에 따른 정확도와 손실을 출력합니다.\n",
    "\n",
    "위와 같은 이미지가 출력됩니다.\n",
    "\n",
    "20회 에포크에서 훈련 정확도는 1.0에 근접한 반면, 테스트의 정확도는 100회 훈련이 끝나도 0.7 수준에 머물고 있습니다.\n",
    "\n",
    "이러한 현상을 과적합 (Overfitting)이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4ro8qBOXptd"
   },
   "source": [
    "# 테스트 이미지 분류하기  \n",
    "아래의 테스트 이미지를 사용해서 훈련된 모델이 개와 고양이 이미지를 분류할 수 있는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3ur0c_2Xhtq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded=files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "\n",
    "  path='/content/' + fn\n",
    "  img=image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "  x=image.img_to_array(img)\n",
    "  x=np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    "\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "\n",
    "  print(classes[0])\n",
    "\n",
    "  if classes[0]>0:\n",
    "    print(fn + \" is a dog\")\n",
    "  else:\n",
    "    print(fn + \" is a cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnjIJ94LXzay"
   },
   "source": [
    "이 코드는 하나 이상의 이미지를 업로드하고, 훈련된 모델을 사용해서 개/고양이 분류 결과를 출력합니다.\n",
    "\n",
    "결과는 위와 같습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7F19o7MUc6L7"
   },
   "source": [
    "[참고한 사이트](https://codetorial.net/tensorflow/classifying_the_cats_and_dogs.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K69-i-t1X1kc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cat_dog_classification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
